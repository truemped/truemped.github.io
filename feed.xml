<?xml version='1.0' encoding='UTF-8'?>
<rss version='2.0' xmlns:atom='http://www.w3.org/2005/Atom'>
<channel>
<atom:link href='http://truemped.github.io/' rel='self' type='application/rss+xml'/>
<title>
all things considered
</title>
<link>
http://truemped.github.io/
</link>
<description>
yet another blog
</description>
<lastBuildDate>
Thu, 28 Sep 2017 22:23:25 +0200
</lastBuildDate>
<generator>
clj-rss
</generator>
<item>
<guid>
http://truemped.github.io/posts/2016-06-18-whatsapp.html
</guid>
<link>
http://truemped.github.io/posts/2016-06-18-whatsapp.html
</link>
<title>
WhatsApp or not
</title>
<description>
&lt;p&gt;I am not using WhatsApp. I also do not have a Facebook account. For Facebook it is easy: I'm just not into sharing my personal life online and keeping in touch with friends can be done without it. WhatsApp is somewhat different. It's basically a replacement of text messages on steroids because you can have groups.&lt;/p&gt;&lt;p&gt;My primary reasons for not using it are: encryption, sharing my phone number with Facebook and open source. For this reason I was and still am promoting &lt;a href='https://whispersystems.org/'&gt;Signal&lt;/a&gt;. The &lt;a href='https://github.com/WhisperSystems'&gt;code&lt;/a&gt; is available for anyone to read and audit and cryptography scientists have reviewed it. You can run your own &lt;a href='https://github.com/WhisperSystems/TextSecure-Server'&gt;server&lt;/a&gt; so you don't rely on any organization to run the server for you.&lt;/p&gt;&lt;p&gt;With the latest news of WhatsApp adding encryption by default and using the Signal protocol this argument is void. So it boils down to the one question: do I trust Facebook with my data? I have no way to check their code and see if there is a backdoor that circumvent the encryption.&lt;/p&gt;&lt;p&gt;But here is the thing: Facebook already has my data. Since WhatsApp downloads the address book of all my friends that have it installed, they already know my phone number. They can even guess what my social network roughly looks like.&lt;/p&gt;&lt;p&gt;So I'm doomed. And I'm asking myself: do I keep being the one person in the room not using WhatsApp?&lt;/p&gt;
</description>
<pubDate>
Sat, 18 Jun 2016 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://truemped.github.io/posts/2016-06-07-failover-continuous-deployment.html
</guid>
<link>
http://truemped.github.io/posts/2016-06-07-failover-continuous-deployment.html
</link>
<title>
Continuous delivery with automatic failover
</title>
<description>
&lt;p&gt;This post is kicking of a little blog series about my adventures into building a fault tolerant Python based web site. The goals are simple:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;two VMs with automatic failover and floating IP&lt;/li&gt;&lt;li&gt;shared filesystem&lt;/li&gt;&lt;li&gt;Debian packages for the Python project&lt;/li&gt;&lt;li&gt;continuous integration&lt;/li&gt;&lt;li&gt;continuous delivery&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In addition to this series of blog posts there will be an example Ansible playbook on Github containing all the relevant roles.&lt;/p&gt;&lt;h3 id=&quot;agenda&quot;&gt;Agenda&lt;/h3&gt;&lt;p&gt;The series is divided into 7 posts. With every new post I will update the links here. They are also available under the tag &lt;a href='/devops-series.html'&gt;devops-series&lt;/a&gt;.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href='/posts/2016-06-07-failover-continuous-deployment.html'&gt;Basics: Debian VM, security and common packages&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Corosync, Pacemaker, Floating IP&lt;/li&gt;&lt;li&gt;Private Networking: TINC&lt;/li&gt;&lt;li&gt;GlusterFS: shared filesystem&lt;/li&gt;&lt;li&gt;Debian package for a Python project&lt;/li&gt;&lt;li&gt;Gitlab, Gitlab-CI and Docker Hub&lt;/li&gt;&lt;li&gt;Gitlab Webhook receiver for deployment&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Obviously this is &lt;strong&gt;a lot&lt;/strong&gt;. So be patient while I write this down.&lt;/p&gt;&lt;h3 id=&quot;digital&amp;#95;ocean&quot;&gt;Digital Ocean&lt;/h3&gt;&lt;p&gt;I chose &lt;a href='https://m.do.co/c/dd5d931d13ce'&gt;Digital Ocean (referral)&lt;/a&gt; for this. There are no particular reasons for it, except a datacenter in Frankfurt, Germany and their great support for APIs. Nothing you wouldn't get at Amazon but maybe a little less &lt;em&gt;enterpsisy&lt;/em&gt; &amp;ndash; whatever that means.&lt;/p&gt;&lt;h3 id=&quot;gitlab&quot;&gt;Gitlab&lt;/h3&gt;&lt;p&gt;Github would be the obvious choice. But budget is small and I need a private repository. Gitlab-CI is integrated directly so I wouldn't need to pay extra for continuous integration. Also Gitlab-CI features build artifacts, which will be the Debian package I then only need to download.&lt;/p&gt;&lt;h3 id=&quot;docker&amp;#95;you&amp;#95;say&quot;&gt;Docker you say&lt;/h3&gt;&lt;p&gt;Another possibility for deployment would be to run everything inside Docker containers. Only for reasons as running out of time I chose not to do this now. It would mean to run everything in containers beginning from Nginx and Varnish down to the databases. Nothing too spectacular but then again I already have the necessary Ansible roles for all components and you shouldn't run Docker in production anyways. At least that is what the Internet tells me. Something like Kubernetes or Docker Swarm would certainly be too much for this.&lt;/p&gt;&lt;h3 id=&quot;debian&amp;#95;vm,&amp;#95;security&amp;#95;and&amp;#95;common&amp;#95;packages&quot;&gt;Debian VM, security and common packages&lt;/h3&gt;&lt;p&gt;Debian is my default solution for running a server. Tons of resources, battle tested and I've been using Debian and/or Ubuntu for more than ten years now. There are however a few things one needs to do in order to secure a server.&lt;/p&gt;&lt;h4 id=&quot;firewall&quot;&gt;Firewall&lt;/h4&gt;&lt;p&gt;I used to write my IPTables rules by hand, nowadays the &lt;a href='https://launchpad.net/ufw'&gt;UFW (uncomplicated firewall)&lt;/a&gt; does a decent job at creating these rules for you in a pretty easy manner. The base setup usually involves disabling all incoming traffic and then only allow the ports you care about:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ ufw default deny incoming&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can even add simple connection rate limiting. Basically this will track connection attempts and if there are more than 6 attempts in the last 30 seconds the connecting IP is automatically banned:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ ufw limit ssh/tcp&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Enable the firewall with:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ ufw enable&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;fail2ban&quot;&gt;Fail2ban&lt;/h4&gt;&lt;p&gt;Now that we have a rate-limiting firewall the next step is to add &lt;a href='http://www.fail2ban.org/'&gt;fail2ban&lt;/a&gt;. Rate limiting is good but you do see many bots that try to guess passwords that are not doing this trying to max-out your bandwidth. This is what fail2ban is for.&lt;/p&gt;&lt;p&gt;It is a simple Python daemon that tails through logfiles and searches for regular expressions. In the SSHD case this might be failed login attempts in &lt;code&gt;/var/log/auth.log&lt;/code&gt;, for NGINX you might find users trying all possible URLs for attacking a Wordpress site, e.g. The default installation comes with many predefined rules that you can enable in &lt;code&gt;/etc/fail2ban/jail.local&lt;/code&gt;.&lt;/p&gt;&lt;h4 id=&quot;secure&amp;#95;sshd&quot;&gt;Secure SSHD&lt;/h4&gt;&lt;p&gt;SSH is already pretty secure but you should follow some additional rules. First we declare the allowed key exchange algorithms, ciphers and macs that the daemon should use in &lt;code&gt;/etc/ssh/sshd&amp;#95;config&lt;/code&gt;. Then you really don't want &lt;strong&gt;root&lt;/strong&gt; to be able to login via SSH and to be really safe we only want to use key-based authentication and disable passwords:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;KexAlgorithms diffie-hellman-group-exchange-sha256
Ciphers aes256-ctr,aes192-ctr,aes128-ctr
MACs hmac-sha2-512,hmac-sha2-256,hmac-ripemd160
PermitRootLogin no
PubkeyAuthentication yes
PasswordAuthentication no&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;rootkithunter&quot;&gt;RootkitHunter&lt;/h4&gt;&lt;p&gt;The final barrier is a locally running root kit hunter. Of course you do your best to not allow anyone gain access to your system but you can never be sure. The &lt;a href='http://rkhunter.sourceforge.net/'&gt;RootkitHunter&lt;/a&gt; is a simple package that scans for known root kits. You can weekly update the database and have a cron job running once a day to scan your system:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ rkhunter --update
$ rkhunter --cron-job&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;common&amp;#95;packages&quot;&gt;Common packages&lt;/h4&gt;&lt;p&gt;Obviously YMMV at this point but my list of common packages I always install contains:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ apt-get install apt-transport-https debian-goodies git htop iftop iotop \\
    atop python-software-properties sudo unattended-upgrades&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is the basic setup of a new VM. Two of them will be used for our production system. The next part will add corosync and pacemaker to both systems in order to automatically set the floating IP to one of the VMs.&lt;/p&gt;
</description>
<pubDate>
Tue, 07 Jun 2016 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://truemped.github.io/posts/2016-02-01-varnish-all-the-things.html
</guid>
<link>
http://truemped.github.io/posts/2016-02-01-varnish-all-the-things.html
</link>
<title>
Varnish all the things
</title>
<description>
&lt;p&gt;My usual web application stack for the past years was based on  a nginx as reverse proxy in front of a number of Python processes. Static resources were served by nginx. Each Python process was stateless, state was stored in some kind of database. If the processes needed some shared ephemeral state like counters a local redis instance solved that. A battle tested common ground for Python based web applications.&lt;/p&gt;&lt;p&gt;What I have added to this lately was &lt;a href='https://www.varnish-cache.org/'&gt;Varnish&lt;/a&gt;, a powerful proxying cache. The first that comes in mind could be &quot;there are two problems in computer science: naming things and cache invalidation&quot;.  Agreed, invalidation is tricky. But there are several tricks at hand that make this not so bad at all.&lt;/p&gt;&lt;p&gt;Note: all examples should work with Varnish 4.0 and greater. If not, drop me a line!&lt;/p&gt;&lt;h3 id=&quot;caching&amp;#95;for&amp;#95;a&amp;#95;very&amp;#95;short&amp;#95;period&quot;&gt;Caching for a very short period&lt;/h3&gt;&lt;p&gt;The first trick is to cache for only a very short amount of time, say 10 seconds or maybe even only 1:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Cache-Control: public, max-age=10&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Say you have a resource that is being hammered a lot and it should be &quot;near real-time&quot;. Varnish will cache this response for 10 seconds. Now after the 10 seconds a new version must be computed. At this point Varnish will queue the incoming requests and only forward one of them to the backend. All &quot;parked&quot; requests will then get the response from the backend. Only one request to the backend every 10 seconds, but there could be billions to Varnish that don't bother you.&lt;/p&gt;&lt;h3 id=&quot;grace&amp;#95;time&quot;&gt;Grace time&lt;/h3&gt;&lt;p&gt;Say you chose to cache for only one second. Everything will be fine then if the backend is able to compute a new version within one second. If it occasionally takes longer then users will have to wait for the backend response. Having users to wait is bad as you might be blocking the browser to render (which you should be avoiding by other means!) or the user sees the loading symbol even though all other elements are already loaded.&lt;/p&gt;&lt;p&gt;Here the grace time helps. It basically means that Varnish will return a stale cache object until the backend is done computing the new version. So let's say the backend sets this header:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Cache-Control: public, max-age=1&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the Varnish VCL you then add:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sub vcl&amp;#95;backend&amp;#95;response {
    set beresp.grace = 1m;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will allow your backend to take up to one minute to compute the new version. During this time Varnish will deliver the old version to all incoming requests. As soon as the backend is finished the new version will be delivered.&lt;/p&gt;&lt;h3 id=&quot;grace&amp;#95;in&amp;#95;times&amp;#95;of&amp;#95;unhealthy&amp;#95;backends&quot;&gt;Grace in times of unhealthy backends&lt;/h3&gt;&lt;p&gt;Grace time can also be extended in order to serve content while the backend is down. For this you need to enable health checking for the backend like so:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;backend server1 {
    .host = &amp;quot;server1.example.com&amp;quot;;
    .probe {
        .url = &amp;quot;/&amp;#95;health&amp;quot;;
        .timeout = 1s;
        .interval = 5s;
        .window = 5;
        .threshold = 3;
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This tells varnish to check the &lt;strong&gt;/_health&lt;/strong&gt; endpoint every five seconds. The backend needs to answer within one second. If three of the last five checks were successful Varnish considers this backend to be healthy.&lt;/p&gt;&lt;p&gt;Now Varnish needs to detect failure and deliver stale content in order to have some time fixing backends. For this we need to modify the &lt;em&gt;vcl_hit&lt;/em&gt; method to increase the grace time to a very large value during times no healthy backend is available.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sub vcl&amp;#95;hit {
    # a cache hit
    if &amp;#40;obj.ttl &amp;gt;= 0s&amp;#41; {
        return &amp;#40;deliver&amp;#41;;
    }
    # object is expired
    if &amp;#40;std.healthy&amp;#40;req.backend&amp;#95;hint&amp;#41;&amp;#41; {
        # but we have a healthy backend
        if &amp;#40;obj.ttl + obj.grace &amp;gt; 0s&amp;#41; {
            # object is within the grace period
            return &amp;#40;deliver&amp;#41;;
        } else {
            # object is outside the grace persiod, fetch a new version
            return&amp;#40;fetch&amp;#41;;
        }
    } else {
        # no healthy backend available, deliver old version for two hours
        if &amp;#40;obj.ttl + 2h &amp;gt; 0s&amp;#41; {
            return &amp;#40;deliver&amp;#41;;
        } else {
            # after two hours we still have no healthy backend, now signal
            # the failure to the user
            return &amp;#40;fetch&amp;#41;;
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you now manage to repair the backend within two hours the user will not &lt;em&gt;see&lt;/em&gt; the outage except maybe for old content.&lt;/p&gt;&lt;h3 id=&quot;purging&amp;#95;the&amp;#95;cache&quot;&gt;Purging the cache&lt;/h3&gt;&lt;p&gt;In order to remove a cache object a special HTTP verb can be used.  By simply accessing the resource that should be removed with a &lt;em&gt;PURGE&lt;/em&gt; verb, e.g., Varnish can dismiss the object. Again this is controlled in the VCL itself:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sub vcl&amp;#95;hit {
    if &amp;#40;req.request == &amp;quot;PURGE&amp;quot;&amp;#41; {
        return&amp;#40;purge&amp;#41;;
        return&amp;#40;synth&amp;#40;200, &amp;quot;Purged&amp;quot;&amp;#41;&amp;#41;;
    }
}
sub vcl&amp;#95;miss {
    if &amp;#40;req.request == &amp;quot;PURGE&amp;quot;&amp;#41; {
        return&amp;#40;purge&amp;#41;;
        return&amp;#40;synth&amp;#40;200, &amp;quot;Purged&amp;quot;&amp;#41;&amp;#41;;
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now executing something like&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ curl -XPURGE &amp;quot;http://www.example.com/recent&amp;quot;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;would purge the cached object. The next &lt;strong&gt;GET&lt;/strong&gt; request issues a new fetch from the backend. Obviously not everyone should be allowed to purge the cache so a simple ACL with white listed IPs blocks unwanted access:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;acl purge {
    &amp;quot;localhost&amp;quot;;
    # add a list of allowed IPs here
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then use it to block access from any other machine:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sub vcl&amp;#95;hit {
    if &amp;#40;req.request == &amp;quot;PURGE&amp;quot;&amp;#41; {
        if &amp;#40;!client.ip &amp;#126; purge&amp;#41; {
            return&amp;#40;synth&amp;#40;405, &amp;quot;Not allowed.&amp;quot;&amp;#41;&amp;#41;;
        }
        return&amp;#40;purge&amp;#41;;
        return&amp;#40;synth&amp;#40;200, &amp;quot;Purged&amp;quot;&amp;#41;&amp;#41;;
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;cache&amp;#95;invalidation&amp;#95;based&amp;#95;on&amp;#95;content&quot;&gt;Cache invalidation based on content&lt;/h3&gt;&lt;p&gt;Sometimes invalidation based on URLs is not sufficient. Let's say one of the articles from the big publishing house had to be removed for legal reasons and you absolutely don't want to show it anymore. Invalidating the whole cache would place quite some load on the backend. Maybe even too much load. In this case banning objects based on its content enables one to only invalidate the &lt;em&gt;affected&lt;/em&gt; objects.&lt;/p&gt;&lt;p&gt;For this we need to introduce a custom HTTP response header from the backend. This could be something like a list of article ids:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Content-Articles: 1,2,3,4,5&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Varnish will store this header along with the object. In order to invalidate all cached objects containing article 3 an artificial endpoint in the VCL is introduced:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sub vcl&amp;#95;recv {
    if &amp;#40;req.url &amp;#126; &amp;quot;/&amp;#95;ban&amp;quot; &amp;amp;&amp;amp; req.method == &amp;quot;BAN&amp;quot;&amp;#41; {
        ban&amp;#40;&amp;quot;obj.http.Content-Articles &amp;#126; &amp;quot; + req.http.Ban-Article&amp;#41;;
        return&amp;#40;synth&amp;#40;204, &amp;quot;NO CONTENT&amp;quot;&amp;#41;&amp;#41;;
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The request to ban article 3 would now be:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ curl -XBAN -H 'Ban-Article: 3' 'http://www.example.com/&amp;#95;ban'&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Again securing via ACL is trivial and left out for clarity.&lt;/p&gt;&lt;p&gt;Banning works slightly different from purging. With purging the object is removed instantly. For each call to ban, Varnish keeps a list of banning statements that live for a longer period of time. When a cached object is requested all of the banning statements are executed against the cached object. If one matches, the object is fetched from the backend and not served. Once all objects have been visited, the banned statement is removed.&lt;/p&gt;&lt;p&gt;In the case of rarely accessed objects, this might never happen. For this the &lt;strong&gt;ban lurker&lt;/strong&gt; thread will iterate over the otherwise missed objects and remove them when necessary.&lt;/p&gt;&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;&lt;p&gt;I hope interest was raised if it has not been present so far. Varnish has helped me a lot over the years and saved a lot of money by reducing the amount of servers necessary for the individual project.&lt;/p&gt;&lt;h4 id=&quot;resources&quot;&gt;Resources&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;a href='https://www.varnish-cache.org/docs/4.0/'&gt;Varnish 4 documentation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://info.varnish-software.com/blog/grace-varnish-4-stale-while-revalidate-semantics-varnish'&gt;Grace time in Varnish 4&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='https://www.varnish-cache.org/docs/4.0/users-guide/vcl-backends.html#health-checks'&gt;Health checks&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://info.varnish-software.com/blog/ban-lurker'&gt;Ban lurker&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
</description>
<pubDate>
Mon, 01 Feb 2016 00:00:00 +0100
</pubDate>
</item>
<item>
<guid>
http://truemped.github.io/posts/2015-07-29-elastic-dsl.html
</guid>
<link>
http://truemped.github.io/posts/2015-07-29-elastic-dsl.html
</link>
<title>
Elasticsearch DSL-DSL
</title>
<description>
&lt;p&gt;Elasticsearch is a search server based on Apache Lucene. As a developer it is easy to use, has an expressive query DSL and all is based on JSON serialization. Often though I find myself in a position where I need to adapt queries frequently and non-trivially, say in a demonstration in front of customers or product owners.&lt;/p&gt;&lt;p&gt;The questions are mostly similar: &quot;what if I also filter for X&quot;, &quot;how does the ranking change, when I add a freshness function&quot;, &quot;do I get a better result if I boost document types Y&quot; and so on. While these are easy to add, two things bother me: first, I need to come up with the queries during a presentation, which adds pauses to the meetings. When I'm finished with the query the discussion has evolved. Second, I don't want to be the enabler. If they can find out what they want without me it also means a faster feedback loop for them. In brainstorming sessions it is easy to focus on arguments and skip the sometimes lengthy query finding pauses. Win win for everyone it seems.&lt;/p&gt;&lt;p&gt;For this I have startet working on &lt;strong&gt;meta-DSLs&lt;/strong&gt; for Elasticsearch projects. The idea is simple: given a base query I want to be able to quickly alter or enhance it using simple functions that are aligned with the mapping and index structure. Given my current addiction towards Clojure, this is what I've come up with:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;query
 &amp;#40;freshness &amp;quot;1h&amp;quot;&amp;#41;
 &amp;#40;tags &amp;#91;&amp;quot;politics&amp;quot; &amp;quot;sports&amp;quot;&amp;#93;&amp;#41;
 &amp;#40;prefer-category {&amp;quot;politics&amp;quot; 2,
                   &amp;quot;sports&amp;quot; 0.5}&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ok, it's not yet a graphical interface, but it is a start. And it's intuitive. After demonstrating this to customers a few times they like it and request more features. Their own feedback loop has shortened considerably. And the best of it is that I am out of the loop and can focus on adding features.&lt;/p&gt;&lt;p&gt;In this example the domain will be news articles. They have a title, tags, a published time and categories. Something like this:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;{
    :title &amp;quot;The news&amp;quot;
    :tags &amp;#91;&amp;quot;obama&amp;quot; &amp;quot;kerry&amp;quot; &amp;quot;merkel&amp;quot;&amp;#93;
    :timestamp &amp;quot;2015-07-28T10:00:00Z&amp;quot;
    :category &amp;#91;&amp;quot;politics&amp;quot;&amp;#93;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This post is my story of how I implemented this. Publishing this as a library might be an idea but in the end all of this is tied to an exact mapping, index structure and use case. If there is interest though, starting something similar in a library could be interesting, if there is interest.&lt;/p&gt;&lt;h2 id=&quot;dsls&amp;#95;in&amp;#95;clojure&quot;&gt;DSLs in Clojure&lt;/h2&gt;&lt;p&gt;Creating a Domain Specific Language is pretty straight forward in Clojure assuming you expose Clojure or Lisp syntax to the user. Using the clojure reader and &lt;code&gt;eval&lt;/code&gt; parsing a DSL into Clojure code is simple and defining the DSL itself does then only involve implementing the functions.&lt;/p&gt;&lt;p&gt;In the next part I focus on the DSL implementation itself and the functions for manipulating the query. In the last section, parsing and evaluating the DSL into a real Elasticsearch query finishes.&lt;/p&gt;&lt;h2 id=&quot;the&amp;#95;dsl&quot;&gt;The DSL&lt;/h2&gt;&lt;p&gt;For the custom DSL I started with a base query structure upon which all other functions build. It has four parts: query, scoring, filtering and aggregations:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def default-query
 {:query
  {:filtered
   {:query {:function&amp;#95;score {:query {}
                             :functions &amp;#91;&amp;#93;}}
    :filter {:bool {:must &amp;#91;&amp;#93;
                    :must&amp;#95;not &amp;#91;&amp;#93;}}}}
  :aggregations {}}&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For all functions I am assuming the query to be the first argument in all functions working with it. This simplifies the code later on as I can use the &lt;code&gt;thread-first&lt;/code&gt; macro to chain the individual function call.&lt;/p&gt;&lt;p&gt;Defining a function to add a &lt;code&gt;query&lt;/code&gt; and for adding aggregations is straight forward and does not even need a helper function:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn- set-query
 &amp;quot;Given a valid ES query `q` add this to the generated query and return the
  new version.&amp;quot;
 &amp;#91;query q&amp;#93;
 &amp;#40;assoc-in query &amp;#91;:query :filtered :query :function&amp;#95;score :query&amp;#93; q&amp;#41;&amp;#41;

&amp;#40;defn- add-aggregation
 &amp;quot;Add a new aggregation to the query&amp;quot;
 &amp;#91;query agg&amp;#93;
 &amp;#40;assoc-in query &amp;#91;:query :aggregations&amp;#93; agg&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To work with this data structure a few helper methods come in handy when developing the individual DSL functions. The first function helps when manipulating lists in a nested map. Basically each scoring function or filter needs to be added like this:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn- append-in-nested-list
 &amp;quot;Given a map, append a new element to a nested  list.&amp;quot;
 &amp;#91;q ks elm&amp;#93;
 &amp;#40;assoc-in q                        ; the query
           ks                       ; the list of keys in the query
           &amp;#40;apply conj              ; append
                  &amp;#40;get-in q ks&amp;#41;     ; to the list
                  elm&amp;#41;&amp;#41;&amp;#41;            ; the new element
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this basic function adding more expressive functions to manipulate the specific parts of the query are easy:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn- add-function-score-function
 &amp;quot;Add a function score function to the query&amp;quot;
 &amp;#91;query fs-function&amp;#93;
 &amp;#40;append-in-nested-list query
                        &amp;#91;:query :filtered :query :function&amp;#95;score :functions&amp;#93;
                        &amp;#91;fs-function&amp;#93;&amp;#41;&amp;#41;

&amp;#40;defn- add-must-filter
 &amp;quot;Add a must filter to the query&amp;quot;
 &amp;#91;query must-filter&amp;#93;
 &amp;#40;append-in-nested-list query
                        &amp;#91;:query :filtered :filter :bool :must&amp;#93;
                        &amp;#91;must-filter&amp;#93;&amp;#41;&amp;#41;

&amp;#40;defn- add-must-not-filter
 &amp;quot;Add a must filter to the query&amp;quot;
 &amp;#91;query must-filter&amp;#93;
 &amp;#40;append-in-nested-list query
                        &amp;#91;:query :filtered :filter :bool :must&amp;#95;not&amp;#93;
                        &amp;#91;must-filter&amp;#93;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;dsl&amp;#95;functions&quot;&gt;DSL functions&lt;/h3&gt;&lt;p&gt;The individual functions now basically compose the DSL. Being able to add &lt;code&gt;&amp;#40;q &amp;quot;merkel&amp;quot;&amp;#41;&lt;/code&gt; is translated into the following Clojure function:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn q
  &amp;quot;Simple query&amp;quot;
  &amp;#91;query user-query&amp;#93;
  &amp;#40;set-query query
             {:query&amp;#95;string {:query user-query
                             :default&amp;#95;operator &amp;quot;AND&amp;quot;}}&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Filtering for tags in our dataset (&lt;code&gt;&amp;#40;tags &amp;#91;&amp;quot;merkel&amp;quot;&amp;#93;&amp;#41;&lt;/code&gt;) is equally trivial:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn tags
  &amp;quot;Filter for a list of tags&amp;quot;
  &amp;#91;query tags&amp;#93;
  &amp;#40;add-must-filter query {:terms {:tags tags}}&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Freshness seems more complicated but in the end I can simply add a function score function using an [exponential decay](). With this the user can even change parameters and see the effects:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn freshness
  &amp;quot;Add freshness preferences to the query. When called with query and hours as
   arguments&amp;quot;
  &amp;#91;query hours&amp;#93;
  &amp;#40;add-function-score-function query
                               {:exp {:publishTime {:decay 0.9
                                                    :scale hours}}}&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Prefering categories over other categories is another function score function. Basically I add a boost (&lt;code&gt;weight&lt;/code&gt;) to all documents matching a certain query:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn prefer-category
  &amp;quot;Prefer categories over all other categories.&amp;quot;
  &amp;#91;query category-preferences&amp;#93;
  &amp;#40;let &amp;#91;nested-keys &amp;#91;:query :filtered :query :function&amp;#95;score :functions&amp;#93;
        functions &amp;#40;map &amp;#40;fn&amp;#91;x&amp;#93; {:filter {:term {:category &amp;#40;first x&amp;#41;}}
                               :weight &amp;#40;second x&amp;#41;}&amp;#41;
                       &amp;#40;seq category-preferences&amp;#41;&amp;#41;
        existing &amp;#40;get-in query nested-keys&amp;#41;&amp;#93;
    &amp;#40;assoc-in query nested-keys &amp;#40;apply conj existing functions&amp;#41;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Aggregations help in understanding the data there is. Classical example in this case would be getting the number of documents in the result set in a category. In ES this is a simple terms aggregation:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn aggregate-categories
 &amp;quot;Aggregate the result by categories.&amp;quot;
 &amp;#91;query&amp;#93;
 &amp;#40;add-aggregation query {:terms {:field :category}}&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To tie everything up I need to be able to wrap all functions into one expression. For this I create a new macro called &lt;code&gt;query&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defmacro query &amp;#91;&amp;amp; body&amp;#93;
`&amp;#40;-&amp;gt; default-query
     &amp;#126;@body&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Using this macro a query can now be defined like this:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def simple-query &amp;#40;query
                   &amp;#40;q &amp;quot;test&amp;quot;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;parsing&amp;#95;the&amp;#95;dsl&quot;&gt;Parsing the DSL&lt;/h2&gt;&lt;p&gt;Doing this is Clojure is nice and easy for me but then again I want the PO not to contact me about getting into the repl. So in the final step I need a function that converts a string to Clojure code. First I need to parse the string using &lt;code&gt;read-string&lt;/code&gt; and then I can &lt;code&gt;eval&lt;/code&gt; the resulting code. For this to work as expected I need to set the special var &lt;code&gt;&amp;#42;ns&amp;#42;&lt;/code&gt; to the namespace of my DSL functions above using the &lt;code&gt;the-ns&lt;/code&gt; function.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;ns demo.dsl&amp;#41;

&amp;#40;defn dsl
 &amp;quot;Compile the DSL string into code&amp;quot;
 &amp;#91;dsl-string&amp;#93;
 &amp;#40;binding &amp;#91;&amp;#42;ns&amp;#42; &amp;#40;the-ns 'demo.dsl-functions&amp;#41;
           &amp;#42;read-eval&amp;#42; false&amp;#93;
  &amp;#40;eval &amp;#40;read-string dsl-string&amp;#41;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;binding&lt;/code&gt; form binds the special var &lt;code&gt;&amp;#42;ns&amp;#42;&lt;/code&gt; to the namespace containing my dsl functions. I also bind &lt;code&gt;&amp;#42;read-eval&amp;#42;&lt;/code&gt; to false and by this disable the &lt;code&gt;eval&lt;/code&gt; function inside the string. The parsed string will have access to all functions declared in there. &lt;code&gt;read-string&lt;/code&gt; converts a string into Clojure code and &lt;code&gt;eval&lt;/code&gt; will execute it. In this case it will simply return the final Elasticsearch query.&lt;/p&gt;&lt;h2 id=&quot;result&quot;&gt;Result&lt;/h2&gt;&lt;p&gt;In essence this allows me to have a web frontend where a user can input the query from the beginning&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;query
 &amp;#40;freshness &amp;quot;1h&amp;quot;&amp;#41;
 &amp;#40;tags &amp;#91;&amp;quot;politics&amp;quot; &amp;quot;sports&amp;quot;&amp;#93;&amp;#41;
 &amp;#40;prefer-category {&amp;quot;politics&amp;quot; 2,
                   &amp;quot;sports&amp;quot; 0.5}&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;get back the equivalent Elasticsearch query:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;{:query
 {:filtered
  {:query
   {:function&amp;#95;score
    {:query {},
     :functions
     &amp;#91;{:exp {:publishTime {:decay 0.9, :scale &amp;quot;1h&amp;quot;}}}
      {:filter {:term {:category &amp;quot;politics&amp;quot;}}, :weight 2}
      {:filter {:term {:category &amp;quot;sports&amp;quot;}}, :weight 0.5}&amp;#93;}},
   :filter
   {:bool
    {:must &amp;#91;{:terms {:tags &amp;#91;&amp;quot;politics&amp;quot; &amp;quot;sports&amp;quot;&amp;#93;}}&amp;#93;, :must&amp;#95;not &amp;#91;&amp;#93;}}}},
 :aggregations {}}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;which I can execute in the backend and display the results. With all the domain functions in place I can then keep on improving the DSL or the frontend and enable the PO to experiment at lot easier without my direct involvement, at least in parts that I am not really interested in.&lt;/p&gt;
</description>
<pubDate>
Wed, 29 Jul 2015 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://truemped.github.io/posts/2015-06-10-init.html
</guid>
<link>
http://truemped.github.io/posts/2015-06-10-init.html
</link>
<title>
Start a blog
</title>
<description>
&lt;p&gt;This is my blog. I haven't really blogged ever. Few people near me do. I so far did not think that I have something interesting to say. And there are already tons of blogs out there which probably have the same contents as this one.&lt;/p&gt;&lt;p&gt;So why do I blog now? First, maybe I'm wrong. And by not blogging I will just never find out. Also, occasionally leaving your comfort zone might not be the worst idea.&lt;/p&gt;&lt;p&gt;Second, I hope to be better at expressing thoughts, ideas and arguments in written form rather than longer discussions over beers or in meetings ad work. Unfortunately I have the habit of basically stop listening when the discussion is getting too long. Talking for the sake of talking is not my business.&lt;/p&gt;&lt;p&gt;Finally, I want to make it a habit. In the past 18 months or so there were ups and downs but overall life is pretty good to me. I've learnt a new programming language (&lt;a href='http://clojure.org'&gt;Clojure&lt;/a&gt;), I'm at &lt;a href='http://www.newyorker.com/culture/culture-desk/zero-dark-inbox'&gt;inbox zero&lt;/a&gt; constantly and just recently I started organizing life and work using &lt;a href='http://orgmode.org/'&gt;org-mode&lt;/a&gt; and &lt;a href='http://gtdfh.branchable.com/'&gt;getting things done&lt;/a&gt;. The next step for me is to flush my head whenever possible and maybe something interesting will be produced as well.&lt;/p&gt;
</description>
<pubDate>
Wed, 10 Jun 2015 00:00:00 +0200
</pubDate>
</item>
</channel>
</rss>
